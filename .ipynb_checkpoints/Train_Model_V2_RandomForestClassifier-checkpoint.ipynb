{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37c74f11-d566-47b2-a214-6b23868ecd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0db94d6-c0eb-4d1e-9f76-bb38b16eb398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define folder paths for each batting shot category\n",
    "folders = {\n",
    "    \"cover_drive\": \"./cover_drive\",\n",
    "    \"pull_shot\": \"./pull_shot\",\n",
    "    \"wrong_shot\": \"./wrong_shot\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46805c49-d29b-4f60-a74e-19f4343290c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data and labels\n",
    "data = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d438e5fe-6742-47c7-8dd4-47172352b1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label mapping\n",
    "label_map = {folder: label for label, folder in enumerate(folders.keys())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ade8361-a97c-430d-b885-edc72730c464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing folder: ./cover_drive, Label: 0\n",
      "Processing folder: ./pull_shot, Label: 1\n",
      "Processing folder: ./wrong_shot, Label: 2\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess data\n",
    "for label, folder_path in enumerate(folders.values()):\n",
    "    print(f\"Processing folder: {folder_path}, Label: {label}\")\n",
    "\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith(\".xlsx\"):\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            \n",
    "            # Load Excel data\n",
    "            df = pd.read_excel(file_path)\n",
    "\n",
    "            # Extract features (flattened time, shoulder, and elbow data)\n",
    "            try:\n",
    "                features = df[[\"Time\", \"LShoulder_Avg\", \"LElbow_Avg\"]].values.flatten()\n",
    "                data.append(features)\n",
    "                labels.append(label)\n",
    "            except KeyError:\n",
    "                print(f\"Missing columns in {file_path}, skipping this file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0e9099a-0560-4dae-bc57-4731f9013fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding to ensure equal-length features\n",
    "max_length = max(len(row) for row in data)\n",
    "data_padded = [np.pad(row, (0, max_length - len(row)), constant_values=0) for row in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c20fbf93-632a-42e0-ad74-83f9ea947ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to NumPy arrays\n",
    "data_array = np.array(data_padded)\n",
    "labels_array = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2a5d5b7-8ec3-4559-b6de-61237e842bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "scaler = StandardScaler()\n",
    "data_normalized = scaler.fit_transform(data_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "deccb3ce-d947-4130-b4af-5142fe2cf158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_normalized, labels_array, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57b31dc7-18b5-4059-8700-37770a0c2bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35725faf-cac2-421b-8684-99494522284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdc1b23e-2843-4dd2-ac96-c0e6fea45e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[36  5  0]\n",
      " [ 4 28  2]\n",
      " [ 1  4  5]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88        41\n",
      "           1       0.76      0.82      0.79        34\n",
      "           2       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.81        85\n",
      "   macro avg       0.78      0.73      0.75        85\n",
      "weighted avg       0.81      0.81      0.81        85\n",
      "\n",
      "\n",
      "Accuracy Score: 0.8117647058823529\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nAccuracy Score:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4f92be01-6fee-43d7-843f-26b2d4692082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and scaler saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model and scaler for future use\n",
    "joblib.dump(model, \"batting_shot_classifier.pkl\")\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "print(\"Model and scaler saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f6cbd7cb-b79c-4e8d-b5da-b63256cc22a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5f1cdc38-ccf1-4dc4-a787-28b722d4d2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model and scaler\n",
    "model = joblib.load(\"batting_shot_classifier.pkl\")\n",
    "scaler = joblib.load(\"scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1e8b00d1-6113-43d0-8dec-de089c9eaae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define label mapping for interpretation\n",
    "label_map = {0: \"cover_drive\", 1: \"pull_shot\", 2: \"wrong_shot\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "58d2aab0-9b91-417f-b842-74e79991d835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the test Excel file\n",
    "test_file_path = \"./combined_Lsh_LEl_angles_Multiprocessing_BasedonTime_7.xlsx\"  # Update with the actual path of your Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "02b506b2-46b4-407b-835e-16e6089f36ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess and predict the category of the shot\n",
    "def predict_shot(file_path):\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        # Load the Excel data\n",
    "        df = pd.read_excel(file_path)\n",
    "\n",
    "        # Check for necessary columns\n",
    "        if not {\"Time\", \"LShoulder_Avg\", \"LElbow_Avg\"}.issubset(df.columns):\n",
    "            print(\"The Excel file is missing required columns: 'Time', 'LShoulder_Avg', 'LElbow_Avg'\")\n",
    "            return\n",
    "\n",
    "        # Extract features and flatten\n",
    "        features = df[[\"Time\", \"LShoulder_Avg\", \"LElbow_Avg\"]].values.flatten()\n",
    "\n",
    "        # Pad features to match training data length\n",
    "        max_length = scaler.mean_.shape[0]\n",
    "        features_padded = np.pad(features, (0, max_length - len(features)), constant_values=0)\n",
    "\n",
    "        # Normalize the features\n",
    "        features_normalized = scaler.transform([features_padded])\n",
    "\n",
    "        # Predict the category\n",
    "        prediction = model.predict(features_normalized)\n",
    "        predicted_label = label_map[prediction[0]]\n",
    "\n",
    "        print(f\"The predicted batting shot category is: {predicted_label}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing the file: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "45366f42-3ec5-4cad-add8-6b29153424f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted batting shot category is: pull_shot\n"
     ]
    }
   ],
   "source": [
    "# Test the model with the Excel file\n",
    "predict_shot(test_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0612848-fe43-4f00-98bb-d82dc926921f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
